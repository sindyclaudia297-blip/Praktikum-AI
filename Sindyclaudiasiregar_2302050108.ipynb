{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHu+qXWVxBzKyp6yT4JgZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindyclaudia297-blip/Praktikum-AI/blob/main/Sindyclaudiasiregar_2302050108.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "s8URuF8mwFK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9482fe73-f409-4c2f-fb61-bac744373edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identitas berhasil dimuat!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "=================================================\n",
        "UJIAN AKHIR PRAKTIKUM KECERDASAN BUATAN\n",
        "Klasifikasi Gambar - Deteksi Pneumonia\n",
        "=================================================\n",
        "Nama Lengkap : [Sindy claudia siregar]\n",
        "NPM          : [2302050108]\n",
        "Kelas        : [IK-4]\n",
        "Tanggal Ujian: []\n",
        "=================================================\n",
        "\"\"\"\n",
        "print(\"Identitas berhasil dimuat!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 1: IMPORT LIBRARY\n",
        "# ==========================================\n",
        "\n",
        "# Library dasar\n",
        "import os, shutil\n",
        "import zipfile\n",
        "import random\n",
        "from random import sample\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm as tq\n",
        "\n",
        "# Library untuk visualisasi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"✓ Library dasar berhasil diimport!\")\n"
      ],
      "metadata": {
        "id": "T7eiMajawbMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c771c74-452d-49da-ede8-a7769af28a79"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Library dasar berhasil diimport!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk pemrosesan gambar\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.transform import resize, rotate, AffineTransform, warp\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.exposure import adjust_gamma\n",
        "from skimage.util import random_noise\n",
        "\n",
        "print(\"✓ Library image processing berhasil diimport!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6QWyvTK7wpG",
        "outputId": "9458841b-adc2-470e-dcec-0532a4846ce0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Library image processing berhasil diimport!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk machine learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, MaxPool2D,\n",
        "                                     Dense, Flatten, Dropout, BatchNormalization)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Nonaktifkan warning\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Cek versi TensorFlow\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(\"✓ Library ML berhasil diimport!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocdx1ZvN71Nq",
        "outputId": "4616899d-69f2-450c-c59a-65df516fb576"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "✓ Library ML berhasil diimport!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 2: DOWNLOAD DATASET DARI KAGGLE\n",
        "# ==========================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"UPLOAD FILE KAGGLE.JSON\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nLangkah:\")\n",
        "print(\"1. Klik 'Choose Files' yang akan muncul di bawah\")\n",
        "print(\"2. Pilih file 'kaggle.json' dari komputer Anda\")\n",
        "print(\"3. Tunggu hingga upload selesai (ada centang hijau)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"\\n✓ Kaggle token berhasil diupload!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "x0QjsG1Y8AMv",
        "outputId": "53fecccf-0058-46e7-98bf-9c862c61a935"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "UPLOAD FILE KAGGLE.JSON\n",
            "==================================================\n",
            "\n",
            "Langkah:\n",
            "1. Klik 'Choose Files' yang akan muncul di bawah\n",
            "2. Pilih file 'kaggle.json' dari komputer Anda\n",
            "3. Tunggu hingga upload selesai (ada centang hijau)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a2db62cb-c97c-4e4b-b65b-cad2f83ee6f4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a2db62cb-c97c-4e4b-b65b-cad2f83ee6f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n",
            "\n",
            "✓ Kaggle token berhasil diupload!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"✓ Kaggle API berhasil dikonfigurasi!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOc91O6D8Ek1",
        "outputId": "e6195526-cd78-4e0c-f809-ac27398cf05c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Kaggle API berhasil dikonfigurasi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset pneumonia dari Kaggle\n",
        "print(\"Downloading dataset... (ini akan memakan waktu 2-5 menit)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!kaggle datasets download -d tolgadincer/labeled-chest-xray-images\n",
        "\n",
        "print(\"\\n✓ Dataset berhasil didownload!\")\n",
        "print(\"\\nExtracting dataset...\")\n",
        "\n",
        "!unzip -q labeled-chest-xray-images.zip\n",
        "\n",
        "print(\"✓ Dataset berhasil diekstrak!\")\n",
        "print(\"\\nStruktur folder:\")\n",
        "!ls -la chest_xray/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv-9rDFh8IoL",
        "outputId": "01e9d5fc-7b9d-481a-9deb-95d0db8242bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset... (ini akan memakan waktu 2-5 menit)\n",
            "==================================================\n",
            "Dataset URL: https://www.kaggle.com/datasets/tolgadincer/labeled-chest-xray-images\n",
            "License(s): other\n",
            "labeled-chest-xray-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "\n",
            "✓ Dataset berhasil didownload!\n",
            "\n",
            "Extracting dataset...\n",
            "replace chest_xray/test/NORMAL/NORMAL-1049278-0001.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 3: DATA PREPARATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"Menggabungkan dataset train dan test...\")\n",
        "\n",
        "# Direktori sumber\n",
        "train_dir = \"chest_xray/train\"\n",
        "test_dir = \"chest_xray/test\"\n",
        "\n",
        "# Direktori tujuan (gabungan)\n",
        "combined_dir = \"chest_xray/dataset\"\n",
        "\n",
        "# Buat folder dataset\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Salin dari train\n",
        "for category in os.listdir(train_dir):\n",
        "    category_dir = os.path.join(train_dir, category)\n",
        "    if os.path.isdir(category_dir):\n",
        "        shutil.copytree(category_dir, os.path.join(combined_dir, category),\n",
        "                       dirs_exist_ok=True)\n",
        "        print(f\"✓ Copied {category} from train\")\n",
        "\n",
        "# Salin dari test\n",
        "for category in os.listdir(test_dir):\n",
        "    category_dir = os.path.join(test_dir, category)\n",
        "    if os.path.isdir(category_dir):\n",
        "        shutil.copytree(category_dir, os.path.join(combined_dir, category),\n",
        "                       dirs_exist_ok=True)\n",
        "        print(f\"✓ Copied {category} from test\")\n",
        "\n",
        "print(\"\\n✓ Dataset berhasil digabungkan!\")\n"
      ],
      "metadata": {
        "id": "v2_Ej6Ws8NZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat dictionary untuk menyimpan daftar gambar\n",
        "lung_image = {}\n",
        "\n",
        "path = \"chest_xray/\"\n",
        "path_sub = os.path.join(path, \"dataset\")\n",
        "\n",
        "for category in os.listdir(path_sub):\n",
        "    lung_image[category] = os.listdir(os.path.join(path_sub, category))\n",
        "    print(f\"{category}: {len(lung_image[category])} gambar\")\n",
        "\n",
        "print(\"\\n✓ Dataset exploration selesai!\")\n"
      ],
      "metadata": {
        "id": "3BXGINuiDQHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan 5 gambar random dari setiap kelas\n",
        "path_sub = \"chest_xray/dataset/\"\n",
        "\n",
        "fig, axs = plt.subplots(len(lung_image.keys()), 5, figsize=(15, 10))\n",
        "\n",
        "for i, class_name in enumerate(os.listdir(path_sub)):\n",
        "    images = np.random.choice(lung_image[class_name], 5, replace=False)\n",
        "\n",
        "    for j, image_name in enumerate(images):\n",
        "        img_path = os.path.join(path_sub, class_name, image_name)\n",
        "        img = Image.open(img_path).convert(\"L\")  # Grayscale\n",
        "        axs[i, j].imshow(img, cmap='gray')\n",
        "        axs[i, j].set(xlabel=class_name, xticks=[], yticks=[])\n",
        "\n",
        "fig.suptitle('Sample Images from Each Class', fontsize=16, y=1.02)\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Visualisasi selesai!\")\n"
      ],
      "metadata": {
        "id": "V9vUR9ZVDSUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung distribusi data\n",
        "lung_path = \"chest_xray/dataset/\"\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(lung_path):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "distribution_df = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "# Plot distribusi\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(x=distribution_df['labels'], palette='Set2')\n",
        "plt.title('Distribusi Data Sebelum Augmentasi', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Kelas')\n",
        "plt.ylabel('Jumlah Gambar')\n",
        "\n",
        "# Tambahkan angka di atas bar\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "                   f'{int(p.get_height())}',\n",
        "                   ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Print statistik\n",
        "print(\"\\nDistribusi Data:\")\n",
        "print(distribution_df['labels'].value_counts())\n",
        "print(f\"\\nTotal gambar: {len(distribution_df)}\")\n"
      ],
      "metadata": {
        "id": "BQFTgKr2Diy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 4: DATA AUGMENTATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"Membuat fungsi augmentasi...\")\n",
        "\n",
        "# Rotasi berlawanan arah jarum jam\n",
        "def anticlockwise_rotation(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    angle = random.randint(0, 180)\n",
        "    return rotate(img, angle)\n",
        "\n",
        "# Rotasi searah jarum jam\n",
        "def clockwise_rotation(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    angle = random.randint(0, 180)\n",
        "    return rotate(img, -angle)\n",
        "\n",
        "# Flip vertikal\n",
        "def flip_up_down(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return np.flipud(img)\n",
        "\n",
        "# Brightness adjustment\n",
        "def add_brightness(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return adjust_gamma(img, gamma=0.5, gain=1)\n",
        "\n",
        "# Blur\n",
        "def blur_image(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return cv2.GaussianBlur(img, (9, 9), 0)\n",
        "\n",
        "# Shear\n",
        "def sheared(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    transform = AffineTransform(shear=0.2)\n",
        "    return warp(img, transform, mode=\"wrap\")\n",
        "\n",
        "# Warp shift\n",
        "def warp_shift(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    transform = AffineTransform(translation=(0, 40))\n",
        "    return warp(img, transform, mode=\"wrap\")\n",
        "\n",
        "print(\"✓ Fungsi augmentasi berhasil dibuat!\")\n",
        "print(\"\\nFungsi yang tersedia:\")\n",
        "print(\"1. Rotation (clockwise & anticlockwise)\")\n",
        "print(\"2. Flip (up-down)\")\n",
        "print(\"3. Brightness adjustment\")\n",
        "print(\"4. Blur\")\n",
        "print(\"5. Shear\")\n",
        "print(\"6. Warp shift\")\n"
      ],
      "metadata": {
        "id": "U0HMHEEdDqJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary transformasi\n",
        "transformations = {\n",
        "    'rotate anticlockwise': anticlockwise_rotation,\n",
        "    'rotate clockwise': clockwise_rotation,\n",
        "    'warp shift': warp_shift,\n",
        "    'blurring image': blur_image,\n",
        "    'add brightness': add_brightness,\n",
        "    'flip up down': flip_up_down,\n",
        "    'shear image': sheared\n",
        "}\n",
        "\n",
        "# Path gambar\n",
        "images_path = \"chest_xray/dataset/NORMAL\"\n",
        "augmented_path = \"chest_xray/dataset/NORMAL\"\n",
        "images = []\n",
        "\n",
        "# Baca semua gambar NORMAL\n",
        "for im in os.listdir(images_path):\n",
        "    images.append(os.path.join(images_path, im))\n",
        "\n",
        "print(f\"Total gambar NORMAL saat ini: {len(images)}\")\n",
        "\n",
        "# Target augmentasi: tambah 2000 gambar\n",
        "images_to_generate = 2000\n",
        "\n",
        "print(f\"\\nMemulai augmentasi untuk menambah {images_to_generate} gambar...\")\n",
        "print(\"Ini akan memakan waktu 3-5 menit. Mohon tunggu...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "i = 1\n",
        "success_count = 0\n",
        "error_count = 0\n",
        "\n",
        "while i <= images_to_generate:\n",
        "    image = random.choice(images)\n",
        "    try:\n",
        "        original_image = io.imread(image)\n",
        "        transformed_image = None\n",
        "        n = 0\n",
        "        transformation_count = random.randint(1, len(transformations))\n",
        "\n",
        "        while n <= transformation_count:\n",
        "            key = random.choice(list(transformations))\n",
        "            transformed_image = transformations[key](original_image)\n",
        "            n += 1\n",
        "\n",
        "        new_image_path = f\"{augmented_path}/augmented_image_{i}.jpg\"\n",
        "        transformed_image = img_as_ubyte(transformed_image)\n",
        "        cv2.imwrite(new_image_path, transformed_image)\n",
        "\n",
        "        success_count += 1\n",
        "\n",
        "        # Progress indicator setiap 100 gambar\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Progress: {i}/{images_to_generate} gambar ({(i/images_to_generate)*100:.1f}%)\")\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        error_count += 1\n",
        "        if error_count < 10:  # Only print first 10 errors\n",
        "            print(f\"Error pada gambar {image}: {str(e)[:50]}...\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n✓ Augmentasi selesai!\")\n",
        "print(f\"Berhasil: {success_count} gambar\")\n",
        "print(f\"Error: {error_count} gambar\")\n"
      ],
      "metadata": {
        "id": "-cJO0o0rERsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung ulang distribusi\n",
        "lung_path = \"chest_xray/dataset/\"\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(lung_path):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "distribution_after = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "# Plot perbandingan\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Before augmentation\n",
        "sns.countplot(x=distribution_df['labels'], palette='Set1', ax=ax1)\n",
        "ax1.set_title('Sebelum Augmentasi', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Kelas')\n",
        "ax1.set_ylabel('Jumlah Gambar')\n",
        "\n",
        "for p in ax1.patches:\n",
        "    ax1.text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "             f'{int(p.get_height())}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# After augmentation\n",
        "sns.countplot(x=distribution_after['labels'], palette='Set2', ax=ax2)\n",
        "ax2.set_title('Setelah Augmentasi', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Kelas')\n",
        "ax2.set_ylabel('Jumlah Gambar')\n",
        "\n",
        "for p in ax2.patches:\n",
        "    ax2.text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "             f'{int(p.get_height())}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistik\n",
        "print(\"\\nDistribusi Setelah Augmentasi:\")\n",
        "print(distribution_after['labels'].value_counts())\n",
        "print(f\"\\nTotal gambar: {len(distribution_after)}\")\n",
        "print(\"\\n✓ Data sudah lebih seimbang!\")\n"
      ],
      "metadata": {
        "id": "5gWvIPLsEqcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 5: DATA SPLITTING\n",
        "# ==========================================\n",
        "\n",
        "mypath = 'chest_xray/dataset/'\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(mypath):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "print(\"DataFrame berhasil dibuat!\")\n",
        "print(f\"Total data: {len(df)}\")\n",
        "print(\"\\nDistribusi per kelas:\")\n",
        "print(df.groupby(['labels']).size())\n"
      ],
      "metadata": {
        "id": "Sj7DlpmIEvB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan features dan labels\n",
        "X = df['path']\n",
        "y = df['labels']\n",
        "\n",
        "# Split 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=300,\n",
        "    stratify=y  # Pastikan distribusi seimbang\n",
        ")\n",
        "\n",
        "print(\"Split berhasil!\")\n",
        "print(f\"Train: {len(X_train)} gambar ({(len(X_train)/len(df))*100:.1f}%)\")\n",
        "print(f\"Test:  {len(X_test)} gambar ({(len(X_test)/len(df))*100:.1f}%)\")\n",
        "\n",
        "# Buat DataFrame terpisah\n",
        "df_train = pd.DataFrame({'path': X_train, 'labels': y_train, 'set': 'train'})\n",
        "df_test = pd.DataFrame({'path': X_test, 'labels': y_test, 'set': 'test'})\n",
        "\n",
        "# Gabungkan\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "print(\"\\nDistribusi per set dan label:\")\n",
        "print(df_all.groupby(['set', 'labels']).size())\n"
      ],
      "metadata": {
        "id": "9ko_007CEzfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path dataset final\n",
        "datasource_path = \"chest_xray/dataset/\"\n",
        "dataset_path = \"Dataset-Final/\"\n",
        "\n",
        "print(\"Membuat struktur folder dan menyalin file...\")\n",
        "print(\"Ini akan memakan waktu 2-3 menit...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "copied_count = 0\n",
        "total_files = len(df_all)\n",
        "\n",
        "for index, row in tq(df_all.iterrows(), total=total_files):\n",
        "    # Get file path\n",
        "    file_path = row['path']\n",
        "\n",
        "    # Buat folder tujuan jika belum ada\n",
        "    dest_dir = os.path.join(dataset_path, row['set'], row['labels'])\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # Tentukan file tujuan\n",
        "    destination_file_name = file_path.split('/')[-1]\n",
        "    file_dest = os.path.join(dest_dir, destination_file_name)\n",
        "\n",
        "    # Copy file\n",
        "    if not os.path.exists(file_dest):\n",
        "        shutil.copy2(file_path, file_dest)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n✓ Selesai! {copied_count} file berhasil disalin\")\n",
        "\n",
        "# Verifikasi struktur\n",
        "print(\"\\nStruktur folder:\")\n",
        "print(f\"Dataset-Final/\")\n",
        "print(f\"├── train/\")\n",
        "print(f\"│   ├── NORMAL/ ({len(os.listdir('Dataset-Final/train/NORMAL'))} files)\")\n",
        "print(f\"│   └── PNEUMONIA/ ({len(os.listdir('Dataset-Final/train/PNEUMONIA'))} files)\")\n",
        "print(f\"└── test/\")\n",
        "print(f\"    ├── NORMAL/ ({len(os.listdir('Dataset-Final/test/NORMAL'))} files)\")\n",
        "print(f\"    └── PNEUMONIA/ ({len(os.listdir('Dataset-Final/test/PNEUMONIA'))} files)\")\n"
      ],
      "metadata": {
        "id": "tCLBYj3yE5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 6: IMAGE DATA GENERATOR\n",
        "# ==========================================\n",
        "\n",
        "# Definisikan direktori\n",
        "TRAIN_DIR = \"Dataset-Final/train/\"\n",
        "TEST_DIR = \"Dataset-Final/test/\"\n",
        "\n",
        "train_normal = os.path.join(TRAIN_DIR, 'NORMAL')\n",
        "train_pneumonia = os.path.join(TRAIN_DIR, 'PNEUMONIA')\n",
        "test_normal = os.path.join(TEST_DIR, 'NORMAL')\n",
        "test_pneumonia = os.path.join(TEST_DIR, 'PNEUMONIA')\n",
        "\n",
        "# Hitung jumlah gambar\n",
        "print(\"Distribusi Data:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training Set:\")\n",
        "print(f\"  - NORMAL: {len(os.listdir(train_normal))} gambar\")\n",
        "print(f\"  - PNEUMONIA: {len(os.listdir(train_pneumonia))} gambar\")\n",
        "print(f\"  - Total: {len(os.listdir(train_normal)) + len(os.listdir(train_pneumonia))} gambar\")\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  - NORMAL: {len(os.listdir(test_normal))} gambar\")\n",
        "print(f\"  - PNEUMONIA: {len(os.listdir(test_pneumonia))} gambar\")\n",
        "print(f\"  - Total: {len(os.listdir(test_normal)) + len(os.listdir(test_pneumonia))} gambar\")\n",
        "print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "EL9asGUfFBQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat ImageDataGenerator dengan normalisasi\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,  # Normalisasi [0, 1]\n",
        "    validation_split=0.2  # 20% untuk validasi\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "# Train generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Data generators berhasil dibuat!\")\n",
        "print(\"\\nClass indices:\")\n",
        "print(train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "zCYF7BqRFGna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 7: MODEL BUILDING\n",
        "# ==========================================\n",
        "\n",
        "# Clear session (jika ada model sebelumnya)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Inisialisasi model\n",
        "model = Sequential(name='Pneumonia_CNN')\n",
        "\n",
        "# BLOCK 1: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                 input_shape=(150, 150, 1), name='conv1'))\n",
        "model.add(BatchNormalization(name='bn1'))\n",
        "model.add(MaxPool2D((2, 2), name='pool1'))\n",
        "\n",
        "# BLOCK 2: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (4, 4), padding='same', activation='relu', name='conv2'))\n",
        "model.add(BatchNormalization(name='bn2'))\n",
        "model.add(MaxPool2D((2, 2), name='pool2'))\n",
        "\n",
        "# BLOCK 3: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (7, 7), padding='same', activation='relu', name='conv3'))\n",
        "model.add(BatchNormalization(name='bn3'))\n",
        "model.add(MaxPool2D((2, 2), name='pool3'))\n",
        "\n",
        "# FLATTEN\n",
        "model.add(Flatten(name='flatten'))\n",
        "\n",
        "# DENSE LAYERS\n",
        "model.add(Dense(128, activation='relu', name='dense1'))\n",
        "model.add(Dropout(0.5, name='dropout1'))\n",
        "\n",
        "model.add(Dense(64, activation='relu', name='dense2'))\n",
        "model.add(Dropout(0.3, name='dropout2'))\n",
        "\n",
        "# OUTPUT LAYER\n",
        "model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "print(\"✓ Model berhasil dibuat!\")\n"
      ],
      "metadata": {
        "id": "8d2hDX5XFNOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Tampilkan summary\n",
        "print(model.summary())\n",
        "\n",
        "# Hitung total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n"
      ],
      "metadata": {
        "id": "Z-mtajbxFU3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 8: TRAINING MODEL\n",
        "# ==========================================\n",
        "\n",
        "# Hitung class weights untuk handle imbalance\n",
        "count_normal = len(os.listdir(train_normal))\n",
        "count_pneumonia = len(os.listdir(train_pneumonia))\n",
        "\n",
        "total = count_normal + count_pneumonia\n",
        "weight_0 = (1 / count_normal) * (total / 2.0)\n",
        "weight_1 = (1 / count_pneumonia) * (total / 2.0)\n",
        "\n",
        "class_weights = {0: weight_0, 1: weight_1}\n",
        "\n",
        "print(\"Class Weights:\")\n",
        "print(f\"NORMAL (0): {weight_0:.4f}\")\n",
        "print(f\"PNEUMONIA (1): {weight_1:.4f}\")\n"
      ],
      "metadata": {
        "id": "t35LFgoFFcFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup callbacks (opsional tapi disarankan)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Training\n",
        "print(\"Memulai training...\")\n",
        "print(\"Ini akan memakan waktu 10-15 menit tergantung GPU\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,  # Sesuaikan dengan waktu yang tersisa\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"✓ Training selesai!\")\n"
      ],
      "metadata": {
        "id": "vwNhy-qcFd3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 9: EVALUATION\n",
        "# ==========================================\n",
        "\n",
        "# Extract history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Create plots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "ax1.plot(epochs_range, acc, 'r', label='Training Accuracy', linewidth=2)\n",
        "ax1.plot(epochs_range, val_acc, 'b', label='Validation Accuracy', linewidth=2)\n",
        "ax1.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss plot\n",
        "ax2.plot(epochs_range, loss, 'r', label='Training Loss', linewidth=2)\n",
        "ax2.plot(epochs_range, val_loss, 'b', label='Validation Loss', linewidth=2)\n",
        "ax2.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Training Metrics:\")\n",
        "print(f\"Training Accuracy: {acc[-1]:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc[-1]:.4f}\")\n",
        "print(f\"Training Loss: {loss[-1]:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss[-1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "lb1wic7mFtAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset test generator\n",
        "test_generator.reset()\n",
        "\n",
        "# Predict\n",
        "print(\"Melakukan prediksi pada test set...\")\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Convert to binary\n",
        "y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(f\"\\n✓ Prediksi selesai!\")\n",
        "print(f\"Total prediksi: {len(y_pred)}\")\n"
      ],
      "metadata": {
        "id": "Y6-O4TThFz62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('Actual Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print CM values\n",
        "print(\"\\nConfusion Matrix Values:\")\n",
        "print(f\"True Negative (TN): {cm[0,0]}\")\n",
        "print(f\"False Positive (FP): {cm[0,1]}\")\n",
        "print(f\"False Negative (FN): {cm[1,0]}\")\n",
        "print(f\"True Positive (TP): {cm[1,1]}\")\n"
      ],
      "metadata": {
        "id": "K_kC6qt0F3N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "report = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=['Normal', 'Pneumonia'],\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(\"\\nCLASSIFICATION REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(report)\n",
        "\n",
        "# Calculate additional metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\nOVERALL METRICS:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Evaluasi\n",
        "if accuracy >= 0.85:\n",
        "    print(\"\\n✓ EXCELLENT! Model mencapai target minimum (≥85%)\")\n",
        "elif accuracy >= 0.80:\n",
        "    print(\"\\n✓ GOOD! Model cukup baik (≥80%)\")\n",
        "else:\n",
        "    print(\"\\n⚠ Model perlu improvement (<80%)\")\n"
      ],
      "metadata": {
        "id": "-8EA8WC1HLl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📋 ANALISIS HASIL MODEL\n",
        "\n",
        "### 1. Performance Summary\n",
        "- **Accuracy**: [97.01]%\n",
        "- **Precision**: [96.22]%\n",
        "- **Recall**: [98.36]%\n",
        "- **F1-Score**: [97.28]%\n",
        "\n",
        "### 2. Interpretasi Confusion Matrix\n",
        "- True Positive (TP): [684]\n",
        "- True Negative (TN): [33]\n",
        "- False Positive (FP): [14]\n",
        "- False Negative (FN): [841]\n",
        "\n",
        "**Analisis:**\n",
        "\n",
        "[Tulis analisis Anda di sini. Contoh:]\n",
        "\n",
        "-Model berhasil mengidentifikasi 684 kasus pneumonia secara benar (True Positive).\n",
        "-Jumlah false negative yang sangat tinggi ini merupakan masalah serius, terutama dalam konteks medis, karena pasien yang sebenarnya sakit berpotensi tidak mendapatkan penanganan yang tepat.\n",
        "-Di sisi lain, jumlah false positive relatif kecil (14 kasus), sehingga kesalahan diagnosis berlebihan terhadap pasien normal cukup rendah.\n",
        "-Nilai true negative yang rendah (33 kasus) mengindikasikan bahwa model masih kurang baik dalam mengenali citra paru-paru normal\n",
        "\n",
        "### 3. Overfitting/Underfitting Assessment\n",
        "**Berdasarkan grafik accuracy dan loss:**\n",
        "### 3. Overfitting / Underfitting Assessment\n",
        "Berdasarkan grafik accuracy dan loss, terlihat bahwa nilai training accuracy mencapai 0.9914, sedangkan validation accuracy sebesar 0.9634. Selisih antara keduanya relatif kecil, sehingga menunjukkan bahwa model mampu melakukan generalisasi dengan cukup baik dan tidak mengalami overfitting yang signifikan.\n",
        "Grafik loss menunjukkan nilai training loss yang sangat rendah (0.0232) dan validation loss yang lebih tinggi (0.1655), namun masih berada dalam batas wajar. Hal ini mengindikasikan adanya kecenderungan overfitting ringan, tetapi masih dapat ditoleransi dan belum berdampak besar terhadap performa model pada data validasi.\n",
        "\n",
        "\n",
        "### 4. Challenges yang Dihadapi\n",
        "[Tuliskan kendala yang Anda hadapi:]\n",
        "\n",
        "1.terdapat dikagle.jsonnya\n",
        "\n",
        "\n",
        "### 5. Improvement Suggestions\n",
        "[Tuliskan ide improvement:]\n",
        "1. Tambah epochs\n",
        "2. Coba arsitektur lain\n",
        "3. Hyperparameter tuning\n",
        "4. Transfer learning\n",
        "5. Dll.\n"
      ],
      "metadata": {
        "id": "67Xg6kI5HvDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 10: SAVE MODEL\n",
        "# ==========================================\n",
        "\n",
        "# Save model\n",
        "model_name = \"pneumonia_detection_model.h5\"\n",
        "model.save(model_name)\n",
        "\n",
        "print(f\"✓ Model berhasil disimpan: {model_name}\")\n",
        "\n",
        "# Download model (opsional)\n",
        "from google.colab import files\n",
        "# files.download(model_name)  # Uncomment untuk download\n"
      ],
      "metadata": {
        "id": "DOJHzBc5LS_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary Report\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RINGKASAN UJIAN AKHIR PRAKTIKUM AI\".center(60))\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nNama: [sindy claudia siregar]\")\n",
        "print(f\"NPM: [2302050108]\")\n",
        "print(f\"Tanggal: [TANGGAL]\")\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"HASIL MODEL\".center(60))\n",
        "print(\"-\" * 60)\n",
        "print(f\"\\nArsitektur: CNN dengan 3 Convolutional Blocks\")\n",
        "print(f\"Total Parameters: {model.count_params():,}\")\n",
        "print(f\"Training Epochs: {len(history.history['accuracy'])}\")\n",
        "print(f\"\\nFinal Metrics:\")\n",
        "print(f\"  - Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  - Precision: {precision:.4f}\")\n",
        "print(f\"  - Recall: {recall:.4f}\")\n",
        "print(f\"  - F1-Score: {f1:.4f}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SELESAI - Silakan screenshot untuk dokumentasi\".center(60))\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "id": "rtdsvICiLXkZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}